{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes\n",
    "import numpy as np\n",
    "import sklearn\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email2vec():\n",
    "    docList = []\n",
    "    classList= []\n",
    "    for i in range(1,26): \n",
    "        wordList = bayes.textParse(open('email/spam/%d.txt' % i,encoding=\"ISO-8859-1\").read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = bayes.textParse(open('email/ham/%d.txt' % i,encoding=\"ISO-8859-1\").read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = bayes.createVocabList(docList)\n",
    "    trainSet = list(range(50))\n",
    "    testSet=[]\n",
    "    for i in range(10):\n",
    "        randIndex = int(np.random.uniform(0,len(trainSet)))#num in 0-49\n",
    "        testSet.append(trainSet[randIndex])\n",
    "        del(trainSet[randIndex])\n",
    "    trainMat = [] \n",
    "    trainClass = []\n",
    "    testMat = [] \n",
    "    testClass = []\n",
    "    for docIndex in trainSet:\n",
    "        trainMat.append(bayes.bagOfWords2Vec(vocabList,docList[docIndex]))\n",
    "        trainClass.append(classList[docIndex])\n",
    "    for docIndex in testSet:\n",
    "        testMat.append(bayes.bagOfWords2Vec(vocabList,docList[docIndex]))\n",
    "        testClass.append(classList[docIndex])\n",
    "    trainMat = np.array(trainMat)\n",
    "    trainClass = np.array(trainClass)\n",
    "    testMat = np.array(testMat)\n",
    "    testClass = np.array(testClass)\n",
    "    return trainMat, trainClass, testMat, testClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9019999999999997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "score = []\n",
    "for i in range(100):\n",
    "    trainMat, trainClass, testMat, testClass = email2vec()\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(trainMat, trainClass)\n",
    "    score.append(clf.score(testMat, testClass))\n",
    "print(\"score:\",sum(score)/len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classfication error ['there', 'was', 'guy', 'the', 'gas', 'station', 'who', 'told', 'that', 'knew', 'mandarin', 'and', 'python', 'could', 'get', 'job', 'with', 'the', 'fbi']\n",
      "classfication error ['linkedin', 'kerry', 'haloney', 'requested', 'add', 'you', 'connection', 'linkedin', 'peter', 'like', 'add', 'you', 'professional', 'network', 'linkedin', 'kerry', 'haloney']\n",
      "classfication error ['hommies', 'just', 'got', 'phone', 'call', 'from', 'the', 'roofer', 'they', 'will', 'come', 'and', 'spaying', 'the', 'foaming', 'today', 'will', 'dusty', 'pls', 'close', 'all', 'the', 'doors', 'and', 'windows', 'could', 'you', 'help', 'close', 'bathroom', 'window', 'cat', 'window', 'and', 'the', 'sliding', 'door', 'behind', 'the', 'don', 'know', 'how', 'can', 'those', 'cats', 'survive', 'sorry', 'for', 'any', 'inconvenience']\n",
      "classfication error ['yeah', 'ready', 'may', 'not', 'here', 'because', 'jar', 'jar', 'has', 'plane', 'tickets', 'germany', 'for']\n",
      "classfication error ['benoit', 'mandelbrot', '1924', '2010', 'benoit', 'mandelbrot', '1924', '2010', 'wilmott', 'team', 'benoit', 'mandelbrot', 'the', 'mathematician', 'the', 'father', 'fractal', 'mathematics', 'and', 'advocate', 'more', 'sophisticated', 'modelling', 'quantitative', 'finance', 'died', '14th', 'october', '2010', 'aged', 'wilmott', 'magazine', 'has', 'often', 'featured', 'mandelbrot', 'his', 'ideas', 'and', 'the', 'work', 'others', 'inspired', 'his', 'fundamental', 'insights', 'you', 'must', 'logged', 'view', 'these', 'articles', 'from', 'past', 'issues', 'wilmott', 'magazine']\n",
      "the error rate is  0.5\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "corpus = []\n",
    "label = []\n",
    "for i in range(1,26): \n",
    "    wordList = open('email/spam/%d.txt' % i,encoding=\"ISO-8859-1\").read()\n",
    "    corpus.append(wordList)\n",
    "    label.append(1)\n",
    "    \n",
    "    wordList = open('email/ham/%d.txt' % i,encoding=\"ISO-8859-1\").read()\n",
    "    corpus.append(wordList)\n",
    "    label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9000000000000008\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tfidfVec = tfidf.fit_transform(X)\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tfidfVec, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score.append(clf.score(X_test, y_test))\n",
    "print(\"score:\",sum(score)/len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class Solution1:\n",
    "    def __init__(self):\n",
    "        self.age = [\"youth\", \"senior\", \"middle_aged\"]\n",
    "        self.income = [\"low\", \"medium\", \"high\"]\n",
    "        self.student = [\"yes\", \"no\"]\n",
    "        self.credit_rating = [\"fair\", \"excellent\"]\n",
    "        \n",
    "    def train(self, data_path):\n",
    "        self.train_data = []\n",
    "        with open(data_path, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter='\\t')\n",
    "            for row in spamreader:\n",
    "                self.train_data.append(row)\n",
    "        self.train_data.pop(0)\n",
    "\n",
    "        self.n_train = len(self.train_data)\n",
    "        \n",
    "        self.age = [x[0] for x in self.train_data]\n",
    "        self.income = [x[1] for x in self.train_data]\n",
    "        self.student = [x[2] for x in self.train_data]\n",
    "        self.credit_rating = [x[3] for x in self.train_data]\n",
    "        self.buy_computer = [x[4] for x in self.train_data]\n",
    "        \n",
    "        self.n_buy_yes = self.buy_computer.count(\"yes\")\n",
    "        self.n_buy_no = self.buy_computer.count(\"no\")\n",
    "        self.p_buy_yes = self.n_buy_yes/self.n_train\n",
    "        self.p_buy_no = self.n_buy_no/self.n_train\n",
    "    \n",
    "    def _count(self, *, age=None, income=None, student=None, credit_rating=None):\n",
    "        print(age, income, student, credit_rating)\n",
    "        for data in self.train_data:\n",
    "            \n",
    "            \n",
    "    \n",
    "    def predit(self, age, income, student, credit_rating):\n",
    "        assert age in self.age \n",
    "        assert income in self.income \n",
    "        assert student in self.student \n",
    "        assert credit_rating in self.credit_rating\n",
    "        \n",
    "        p_yes = ((self.age.count(age) / self.n_buy_yes) \n",
    "        * (self.income.count(income) / self.n_buy_yes) \n",
    "        * (self.student.count(student) / self.n_buy_yes) \n",
    "        * (self.credit_rating.count(credit_rating) / self.n_buy_yes) \n",
    "        * self.p_buy_yes)\n",
    "        \n",
    "        p_no = ((self.age.count(age) / self.n_buy_no) \n",
    "        * (self.income.count(income) / self.n_buy_no) \n",
    "        * (self.student.count(student) / self.n_buy_no) \n",
    "        * (self.credit_rating.count(credit_rating) / self.n_buy_no) \n",
    "        * self.p_buy_no)\n",
    "        \n",
    "        print(self.age.count(age))\n",
    "        print(p_yes, p_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 None None None\n"
     ]
    }
   ],
   "source": [
    "example1 = Solution1()\n",
    "example1._count(age=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.16460905349794236 0.9600000000000001\n"
     ]
    }
   ],
   "source": [
    "example1 = Solution1()\n",
    "example1.train('./example1.csv')\n",
    "example1.predit(\"youth\", \"medium\", \"yes\", \"fair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
