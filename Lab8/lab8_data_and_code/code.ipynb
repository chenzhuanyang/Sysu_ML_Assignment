{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes\n",
    "import numpy as np\n",
    "import sklearn\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email2vec():\n",
    "    docList = []\n",
    "    classList= []\n",
    "    for i in range(1,26): \n",
    "        wordList = bayes.textParse(open('email/spam/%d.txt' % i,encoding=\"ISO-8859-1\").read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = bayes.textParse(open('email/ham/%d.txt' % i,encoding=\"ISO-8859-1\").read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = bayes.createVocabList(docList)\n",
    "    trainSet = list(range(50))\n",
    "    testSet=[]\n",
    "    for i in range(10):\n",
    "        randIndex = int(np.random.uniform(0,len(trainSet)))#num in 0-49\n",
    "        testSet.append(trainSet[randIndex])\n",
    "        del(trainSet[randIndex])\n",
    "    trainMat = [] \n",
    "    trainClass = []\n",
    "    testMat = [] \n",
    "    testClass = []\n",
    "    for docIndex in trainSet:\n",
    "        trainMat.append(bayes.bagOfWords2Vec(vocabList,docList[docIndex]))\n",
    "        trainClass.append(classList[docIndex])\n",
    "    for docIndex in testSet:\n",
    "        testMat.append(bayes.bagOfWords2Vec(vocabList,docList[docIndex]))\n",
    "        testClass.append(classList[docIndex])\n",
    "    trainMat = np.array(trainMat)\n",
    "    trainClass = np.array(trainClass)\n",
    "    testMat = np.array(testMat)\n",
    "    testClass = np.array(testClass)\n",
    "    return trainMat, trainClass, testMat, testClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9019999999999997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "score = []\n",
    "for i in range(100):\n",
    "    trainMat, trainClass, testMat, testClass = email2vec()\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(trainMat, trainClass)\n",
    "    score.append(clf.score(testMat, testClass))\n",
    "print(\"score:\",sum(score)/len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classfication error ['there', 'was', 'guy', 'the', 'gas', 'station', 'who', 'told', 'that', 'knew', 'mandarin', 'and', 'python', 'could', 'get', 'job', 'with', 'the', 'fbi']\n",
      "classfication error ['linkedin', 'kerry', 'haloney', 'requested', 'add', 'you', 'connection', 'linkedin', 'peter', 'like', 'add', 'you', 'professional', 'network', 'linkedin', 'kerry', 'haloney']\n",
      "classfication error ['hommies', 'just', 'got', 'phone', 'call', 'from', 'the', 'roofer', 'they', 'will', 'come', 'and', 'spaying', 'the', 'foaming', 'today', 'will', 'dusty', 'pls', 'close', 'all', 'the', 'doors', 'and', 'windows', 'could', 'you', 'help', 'close', 'bathroom', 'window', 'cat', 'window', 'and', 'the', 'sliding', 'door', 'behind', 'the', 'don', 'know', 'how', 'can', 'those', 'cats', 'survive', 'sorry', 'for', 'any', 'inconvenience']\n",
      "classfication error ['yeah', 'ready', 'may', 'not', 'here', 'because', 'jar', 'jar', 'has', 'plane', 'tickets', 'germany', 'for']\n",
      "classfication error ['benoit', 'mandelbrot', '1924', '2010', 'benoit', 'mandelbrot', '1924', '2010', 'wilmott', 'team', 'benoit', 'mandelbrot', 'the', 'mathematician', 'the', 'father', 'fractal', 'mathematics', 'and', 'advocate', 'more', 'sophisticated', 'modelling', 'quantitative', 'finance', 'died', '14th', 'october', '2010', 'aged', 'wilmott', 'magazine', 'has', 'often', 'featured', 'mandelbrot', 'his', 'ideas', 'and', 'the', 'work', 'others', 'inspired', 'his', 'fundamental', 'insights', 'you', 'must', 'logged', 'view', 'these', 'articles', 'from', 'past', 'issues', 'wilmott', 'magazine']\n",
      "the error rate is  0.5\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "corpus = []\n",
    "label = []\n",
    "for i in range(1,26): \n",
    "    wordList = open('email/spam/%d.txt' % i,encoding=\"ISO-8859-1\").read()\n",
    "    corpus.append(wordList)\n",
    "    label.append(1)\n",
    "    \n",
    "    wordList = open('email/ham/%d.txt' % i,encoding=\"ISO-8859-1\").read()\n",
    "    corpus.append(wordList)\n",
    "    label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9000000000000008\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tfidfVec = tfidf.fit_transform(X)\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tfidfVec, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score.append(clf.score(X_test, y_test))\n",
    "print(\"score:\",sum(score)/len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class Solution1:\n",
    "    def __init__(self):\n",
    "        self.age = [\"youth\", \"senior\", \"middle_aged\"]\n",
    "        self.income = [\"low\", \"medium\", \"high\"]\n",
    "        self.student = [\"yes\", \"no\"]\n",
    "        self.credit_rating = [\"fair\", \"excellent\"]\n",
    "        \n",
    "    def train(self, data_path):\n",
    "        self.train_data = []\n",
    "        with open(data_path, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter='\\t')\n",
    "            for row in spamreader:\n",
    "                self.train_data.append(row)\n",
    "        self.train_data.pop(0)\n",
    "\n",
    "        self.n_train = len(self.train_data)\n",
    "        \n",
    "        self.buy_computer = [x[4] for x in self.train_data]\n",
    "        \n",
    "        self.n_buy_yes = self.buy_computer.count(\"yes\")\n",
    "        self.n_buy_no = self.buy_computer.count(\"no\")\n",
    "        self.p_buy_yes = self.n_buy_yes/self.n_train\n",
    "        self.p_buy_no = self.n_buy_no/self.n_train\n",
    "    \n",
    "    def _count(self, count_key, count_value, buy_computer):\n",
    "        key = [\"age\", \"income\", \"student\", \"credit_rating\"]\n",
    "        index = key.index(count_key)\n",
    "        count = 0\n",
    "        for data in self.train_data:\n",
    "            if data[index] == count_value and data[4] == buy_computer:\n",
    "                count += 1\n",
    "                \n",
    "        return count\n",
    "    \n",
    "    def predit(self, age, income, student, credit_rating):\n",
    "        assert age in self.age \n",
    "        assert income in self.income \n",
    "        assert student in self.student \n",
    "        assert credit_rating in self.credit_rating\n",
    "        \n",
    "        p_yes = ((self._count(\"age\", age, \"yes\") / self.n_buy_yes) \n",
    "        * (self._count(\"income\", income, \"yes\") / self.n_buy_yes) \n",
    "        * (self._count(\"student\", student, \"yes\") / self.n_buy_yes) \n",
    "        * (self._count(\"credit_rating\", credit_rating, \"yes\") / self.n_buy_yes) \n",
    "        * self.p_buy_yes)\n",
    "        \n",
    "        p_no = ((self._count(\"age\", age, \"no\") / self.n_buy_no) \n",
    "        * (self._count(\"income\", income, \"no\") / self.n_buy_no) \n",
    "        * (self._count(\"student\", student, \"no\") / self.n_buy_no) \n",
    "        * (self._count(\"credit_rating\", credit_rating, \"no\") / self.n_buy_no) \n",
    "        * self.p_buy_no)\n",
    "        \n",
    "        if p_yes > p_no:\n",
    "            print(\"predit result: yes\")\n",
    "        else:\n",
    "            print(\"predit result: no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predit result: yes\n"
     ]
    }
   ],
   "source": [
    "example1 = Solution1()\n",
    "example1.train('./example1.csv')\n",
    "example1.predit(\"youth\", \"medium\", \"yes\", \"fair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution2():\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    \n",
    "    def train(self, data_path):\n",
    "        self.train_data = []\n",
    "        self.male = []\n",
    "        self.female = []\n",
    "        with open(data_path, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter='\\t')\n",
    "            for row in spamreader:\n",
    "                self.train_data.append(row)\n",
    "        self.train_data.pop(0)\n",
    "\n",
    "        self.n_train = len(self.train_data)\n",
    "        \n",
    "        for data in self.train_data:\n",
    "            if data[0] == '男':\n",
    "                self.male.append(data[1:])\n",
    "            else:\n",
    "                self.female.append(data[1:])\n",
    "        \n",
    "        self.male = np.array(self.male, dtype = np.float)\n",
    "        self.female = np.array(self.female, dtype = np.float)\n",
    "        \n",
    "        self.male_height_means = np.mean(self.male[:,0])\n",
    "        self.male_weight_means = np.mean(self.male[:,1])\n",
    "        self.male_footsize_means = np.mean(self.male[:,2])\n",
    "        self.male_height_var = np.var(self.male[:,0], ddof=1)\n",
    "        self.male_weight_var = np.var(self.male[:,1], ddof=1)\n",
    "        self.male_footsize_var = np.var(self.male[:,2], ddof=1)\n",
    "        \n",
    "        self.female_height_means = np.mean(self.female[:,0])\n",
    "        self.female_weight_means = np.mean(self.female[:,1])\n",
    "        self.female_footsize_means = np.mean(self.female[:,2])\n",
    "        self.female_height_var = np.var(self.female[:,0], ddof=1)\n",
    "        self.female_weight_var = np.var(self.female[:,1], ddof=1)\n",
    "        self.female_footsize_var = np.var(self.female[:,2], ddof=1)\n",
    "        \n",
    "    def helper(self, x, means, var):\n",
    "        return np.exp((-((x - means) ** 2)) / (2 * var)) / (np.sqrt(2*np.pi) * var ** 0.5)\n",
    "\n",
    "        \n",
    "    def predit(self, height, weight, footsize):\n",
    "        p_male = (self.helper(height, self.male_height_means, self.male_height_var) *\n",
    "                  self.helper(weight, self.male_weight_means, self.male_weight_var) *\n",
    "                  self.helper(footsize, self.male_footsize_means, self.male_footsize_var)) * 0.5\n",
    "        \n",
    "        p_female = (self.helper(height, self.female_height_means, self.female_height_var) *\n",
    "                  self.helper(weight, self.female_weight_means, self.female_weight_var) *\n",
    "                  self.helper(footsize, self.female_footsize_means, self.female_footsize_var))\n",
    "        \n",
    "        if p_male > p_female:\n",
    "            print(\"predit result: male\")\n",
    "        else:\n",
    "            print(\"predit result: female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predit result: female\n"
     ]
    }
   ],
   "source": [
    "example2 = Solution2()\n",
    "example2.train(\"./example2.csv\")\n",
    "example2.predit(6, 130, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn2\n",
    "import knn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "datingDataMat, datingLabels = knn2.file2matrix('datingTestSet2.txt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(datingDataMat, datingLabels, \n",
    "                                                   test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "gnb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = knn3.createDataSet('./trainingDigits/')\n",
    "x_test, y_test = knn3.createDataSet('./testDigits/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9312896405919662"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
